# -*- coding: utf-8 -*-
"""
Streamlit â€“ Inventaire RPA Generali (v3.4 â€¢ 2025-06-05)
Auteur : Samir El Hassani â€“ Avanade
Correctifs & complÃ©tude :
 â€¢ lecture XLS/XLSX ou CSV (Sheet 1)
 â€¢ dÃ©tection automatique de la bonne ligne dâ€™en-tÃªtes
 â€¢ mappage flexible des noms de colonnes
 â€¢ toutes les visualisations initiales + onglets ComplexitÃ© / Tech-Stack
 â€¢ aucun crash si colonne manquante
"""

from __future__ import annotations
import csv, io, itertools, re, unicodedata, warnings, pathlib
import numpy as np
import pandas as pd
import scipy.stats as stats
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# â•â•â•â•â•â•â•â•â•â•â•â• CONFIG â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config("Inventaire RPA Generali", "ğŸ¤–", "wide")
pd.options.display.float_format = "{:,.2f}".format
alt.data_transformers.disable_max_rows()
AUTHOR, REPO = "Samir El Hassani", "https://github.com/samirelhassani1998/Avanade"

# â•â•â•â•â•â•â•â•â•â•â•â• UTILS â•â•â•â•â•â•â•â•â•â•â•â•
def slugify(txt: str) -> str:
    txt = unicodedata.normalize("NFKD", str(txt)).encode("ascii", "ignore").decode()
    return re.sub(r"_+", "_", re.sub(r"[^0-9a-z]+", "_", txt.lower())).strip("_")

def read_any(buf) -> pd.DataFrame:
    """Lit CSV ou Excel (1Ê³áµ‰ feuille)."""
    name = pathlib.Path(getattr(buf, "name", "file")).suffix.lower()
    if name in (".xls", ".xlsx", ".xlsm"):
        return pd.read_excel(buf, sheet_name=0, dtype=str, keep_default_na=False)
    raw = buf.read()
    sample = raw[:2048].decode("utf-8", "replace")
    try:
        sep = csv.Sniffer().sniff(sample, [",", ";", "\t"]).delimiter
    except csv.Error:
        sep = ","
    buf.seek(0)
    return pd.read_csv(io.BytesIO(raw), sep=sep, dtype=str, keep_default_na=False)

def promote_header_auto(df: pd.DataFrame) -> pd.DataFrame:
    """Si la 1Ê³áµ‰ ligne contient Â« Id Â» & Â« Nom Â», on la prend comme header."""
    if len(df) and {"id", "nom"}.issubset(df.iloc[0].str.strip().str.lower()):
        df = df.iloc[1:].reset_index(drop=True)
        df.columns = df.iloc[0].str.strip().str.lower()
    return df

def to_num(s: pd.Series, pct=False):
    s = (s.astype(str)
           .str.replace("%", "", regex=False)
           .str.replace(",", "", regex=False)
           .str.replace(" ", "", regex=False)
           .str.strip())
    n = pd.to_numeric(s, errors="coerce")
    return n/100 if pct else n

def clean(df0: pd.DataFrame) -> pd.DataFrame:
    df = promote_header_auto(df0)
    df.dropna(axis=1, how="all", inplace=True)
    df.columns = [slugify(c) or f"col_{i}" for i, c in enumerate(df.columns)]

    mapping = {"volumetrie_an": False, "gains_etp": False,
               "reussite": True, "%reussite": True}
    for raw, pct in mapping.items():
        col = next((c for c in df.columns if c.startswith(raw)), None)
        if col:
            df[col] = to_num(df[col], pct)
            df.rename(columns={col: raw}, inplace=True)

    if "synch_asynch" in df:            # mode synchrone / asynchrone
        df["synch_mode"] = df["synch_asynch"].str.lower().str.strip()
    if "complexite_s_m_l" in df:        # complexitÃ© S/M/L
        df["complexite_cat"] = (df["complexite_s_m_l"].str.upper().str[0]
                                .map({"S": "Small", "M": "Medium", "L": "Large"}))
    return df

@st.cache_data(show_spinner=False)
def profile(df: pd.DataFrame):
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        d = df.describe(include="all")
    total = len(df)
    p = (d.T.assign(dtype=df.dtypes.astype(str))
            .reset_index().rename(columns={"index": "col"}))
    p["count"] = pd.to_numeric(p["count"], errors="coerce").fillna(0)
    p["missing"] = total - p["count"]
    p["missing_pct"] = (p["missing"] / total * 100).round(1)
    return p

@st.cache_data(show_spinner=False)
def corr_with_p(df):
    num = df.select_dtypes(np.number)
    out = []
    for a, b in itertools.combinations(num.columns, 2):
        valid = num[[a, b]].dropna()
        if len(valid) < 3:
            continue
        r, p = stats.pearsonr(valid[a], valid[b])
        out.append({"var_x": a, "var_y": b, "corr": r, "pval": p})
    return pd.DataFrame(out)

# â•â•â•â•â•â•â•â•â•â•â•â• SIDE BAR â•â•â•â•â•â•â•â•â•â•â•â•
st.sidebar.header("ğŸ“‚ Import")
upl = st.sidebar.file_uploader("Excel ou CSV", ["csv", "xls", "xlsx", "xlsm"])
if upl is None:
    st.sidebar.info("â¡ï¸ DÃ©posez un fichier pour commencer."); st.stop()

df = clean(read_any(upl))

if st.sidebar.checkbox("ğŸ‘€ Colonnes", False):
    st.sidebar.write(df.columns.tolist())

with st.sidebar:
    st.markdown("### ğŸ›ï¸ Filtres")
    filt_cat = {"zone_fonctionnelle": "Zone",
                "departement": "DÃ©partement",
                "complexite_cat": "ComplexitÃ©",
                "synch_mode": "Synch/Asynch"}
    for col, lab in filt_cat.items():
        if col in df and df[col].notna().any():
            sel = st.multiselect(lab, sorted(df[col].dropna().unique()),
                                 default=list(sorted(df[col].dropna().unique())))
            df = df[df[col].isin(sel)]

    if "volumetrie_an" in df:
        v = df["volumetrie_an"].dropna()
        r = st.slider("VolumÃ©trie/an", float(v.min()), float(v.max()),
                      (float(v.min()), float(v.max())))
        df = df[df["volumetrie_an"].between(*r)]

    if "reussite" in df:
        pct = st.slider("% rÃ©ussite", 0.0, 1.0, (0.0, 1.0))
        df = df[df["reussite"].between(*pct)]

# â•â•â•â•â•â•â•â•â•â•â•â• KPI â•â•â•â•â•â•â•â•â•â•â•â•
st.success(f"{len(df):,} lignes Ã— {df.shape[1]} colonnes sÃ©lectionnÃ©es")
k1, k2, k3, k4, k5 = st.columns(5)
k1.metric("Robots", f"{len(df):,}")
if "volumetrie_an" in df:
    k2.metric("VolumÃ©trie totale", f"{df['volumetrie_an'].sum():,.0f}")
if "reussite" in df:
    k3.metric("MÃ©diane % rÃ©ussite", f"{df['reussite'].median()*100:,.1f}%")
    k4.metric("Robots < 60 %", int((df["reussite"] < .6).sum()))
if "gains_etp" in df:
    k5.metric("Gains ETP", f"{df['gains_etp'].sum():,.1f}")

# â•â•â•â•â•â•â•â•â•â•â•â• TABS â•â•â•â•â•â•â•â•â•â•â•â•
tabs = st.tabs(["Vue gÃ©nÃ©rale", "Distributions", "Relations", "Performance",
                "Heat-Zones", "Clustering", "ComplexitÃ© / Mode",
                "Tech-Stack", "DonnÃ©es"])
(tab_over, tab_dist, tab_rel, tab_perf,
 tab_heat, tab_clu, tab_comp, tab_tech, tab_data) = tabs

# â•â•â• 1. Vue gÃ©nÃ©rale (Pareto + agrÃ©gats) â•â•â•
with tab_over:
    st.subheader("ğŸ“ˆ Pareto 80/20 volumÃ©trie")
    if {"volumetrie_an", "nom"}.issubset(df):
        pareto = (df.dropna(subset=["volumetrie_an"])
                    .sort_values("volumetrie_an", ascending=False)
                    .reset_index(drop=True))
        pareto["cum_pct"] = (pareto["volumetrie_an"].cumsum()
                             / pareto["volumetrie_an"].sum())
        st.altair_chart(
            alt.layer(
                alt.Chart(pareto.head(20)).mark_bar().encode(
                    x=alt.X("nom:N", sort="-y", axis=alt.Axis(title=None,
                                                              labels=False)),
                    y="volumetrie_an:Q",
                    tooltip=["nom", "volumetrie_an"]),
                alt.Chart(pareto.head(20)).mark_line(point=True,
                                                     color="#F39C12").encode(
                    x="nom:N",
                    y=alt.Y("cum_pct:Q", axis=alt.Axis(format="%")),
                    tooltip=alt.Tooltip("cum_pct:Q", format=".1%"))
            ).resolve_scale(y="independent").properties(height=400),
            use_container_width=True)

    if "zone_fonctionnelle" in df:
        st.dataframe(
            df.groupby("zone_fonctionnelle")
              .agg(robots=("nom", "count"),
                   volumetrie=("volumetrie_an", "sum"),
                   reussite_moy=("reussite", "mean"))
              .reset_index(),
            hide_index=True, use_container_width=True)

# â•â•â• 2. Distributions â•â•â•
with tab_dist:
    st.subheader("ğŸ“Š Histogramme & box-plot")
    nums = df.select_dtypes(np.number).columns
    if len(nums):
        var = st.selectbox("Variable numÃ©rique", nums)
        c1, c2 = st.columns(2)
        c1.altair_chart(
            alt.Chart(df.dropna(subset=[var]))
               .mark_bar().encode(x=alt.X(var, bin=alt.Bin(maxbins=50)),
                                  y='count()'),
            use_container_width=True)
        c2.altair_chart(
            alt.Chart(df.dropna(subset=[var])).mark_boxplot(extent="min-max")
               .encode(y=var),
            use_container_width=True)
    else:
        st.info("Aucune variable numÃ©rique dÃ©tectÃ©e.")

# â•â•â• 3. Relations â•â•â•
with tab_rel:
    st.subheader("ğŸ”— CorrÃ©lations & nuage")
    nums = df.select_dtypes(np.number).columns
    if len(nums) >= 2:
        cd = corr_with_p(df)
        if not cd.empty:
            st.altair_chart(
                alt.Chart(cd).mark_rect().encode(
                    x="var_x:O", y="var_y:O",
                    color=alt.Color("corr:Q", scale=alt.Scale(scheme="viridis")),
                    tooltip=[alt.Tooltip("corr:Q", format=".2f"),
                             alt.Tooltip("pval:Q", format=".2e")]),
                use_container_width=True)
    if {"volumetrie_an", "reussite"}.issubset(df):
        base = df.dropna(subset=["volumetrie_an", "reussite"])
        st.altair_chart(
            (alt.Chart(base).mark_circle(size=70, opacity=.6)
                 .encode(x="volumetrie_an", y=alt.Y("reussite",
                                                    axis=alt.Axis(format="%")),
                         tooltip=list(df.columns)))
            + (alt.Chart(base).transform_regression("volumetrie_an",
                                                    "reussite")
                 .mark_line(color="red")),
            use_container_width=True)

# â•â•â• 4. Performance (distribution gaussienne) â•â•â•
with tab_perf:
    st.subheader("ğŸ“ Ajustement gaussien")
    numcols = df.select_dtypes(np.number).columns
    if numcols.any():
        var = st.selectbox("Variable", numcols)
        data = df[var].dropna()
        if len(data) > 3:
            mu, sig = data.mean(), data.std()
            x = np.linspace(data.min(), data.max(), 200)
            fig = go.Figure()
            fig.add_histogram(x=data, nbinsx=40, histnorm='probability density',
                              name="Empirique")
            fig.add_scatter(x=x, y=stats.norm.pdf(x, mu, sig),
                            mode='lines', name=f"N({mu:.1f},{sig:.1f}Â²)")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Pas assez de valeurs.")

# â•â•â• 5. Heat-Zones â•â•â•
with tab_heat:
    st.subheader("ğŸŒ¡ï¸ Heatmap Zone Ã— classe de % rÃ©ussite")
    needed = {"zone_fonctionnelle", "reussite", "volumetrie_an"}
    if needed.issubset(df):
        bins = [0, .6, .8, 1.01]
        labels = ["<60 %", "60â€’80 %", "â‰¥80 %"]
        df["classe_reussite"] = pd.cut(df["reussite"], bins=bins,
                                       labels=labels, include_lowest=True)
        metric = st.radio("Couleur basÃ©e sur :", ["Nombre de robots",
                                                  "VolumÃ©trie totale"],
                          horizontal=True)
        if metric == "Nombre de robots":
            pv = (df.groupby(["zone_fonctionnelle", "classe_reussite"])
                    .size().reset_index(name="val"))
            titre = "Robots"
        else:
            pv = (df.groupby(["zone_fonctionnelle", "classe_reussite"])
                    ["volumetrie_an"].sum().reset_index(name="val"))
            titre = "VolumÃ©trie"
        st.altair_chart(
            alt.Chart(pv).mark_rect().encode(
                x="classe_reussite:N", y="zone_fonctionnelle:N",
                color=alt.Color("val:Q", scale=alt.Scale(scheme="blues"),
                                title=titre),
                tooltip=["zone_fonctionnelle:N", "classe_reussite:N",
                         alt.Tooltip("val:Q", format=",.0f", title=titre)]),
            use_container_width=True)
    else:
        st.info("Colonnes manquantes.")

# â•â•â• 6. Clustering K-means â•â•â•
with tab_clu:
    st.subheader("ğŸ¯ Clustering K-means")
    feats = ["volumetrie_an", "reussite", "gains_etp"]
    feats = [c for c in feats if c in df]
    numc = df[feats].dropna()
    if numc.shape[0] >= 5 and numc.shape[1] >= 2:
        ks = st.slider("k clusters", 2, 6, 3)
        scaled = StandardScaler().fit_transform(numc)
        km = KMeans(n_clusters=ks, random_state=0, n_init="auto").fit(scaled)
        df.loc[numc.index, "cluster"] = km.labels_
        st.metric("Inertie", f"{km.inertia_:,.0f}")
        x, y = st.selectbox("Axe X", feats, 0), st.selectbox("Axe Y", feats, 1)
        st.plotly_chart(
            px.scatter(df, x=x, y=y, color="cluster",
                       hover_data=["nom"]+feats), use_container_width=True)
    else:
        st.info("Minimum : 5 lignes & 2 variables numÃ©riques.")

# â•â•â• 7. ComplexitÃ© / Synch â•â•â•
with tab_comp:
    st.header("ğŸ” ComplexitÃ© & Synch/Asynch")
    c1, c2 = st.columns(2)

    if "complexite_cat" in df:
        c1.plotly_chart(px.pie(df, names="complexite_cat", hole=.45,
                               title="RÃ©partition par complexitÃ©"),
                        use_container_width=True)
        if "volumetrie_an" in df:
            vol = df.groupby("complexite_cat")["volumetrie_an"].sum().reset_index()
            c2.plotly_chart(px.bar(vol, x="complexite_cat", y="volumetrie_an",
                                   title="VolumÃ©trie par complexitÃ©"),
                            use_container_width=True)

    if "synch_mode" in df:
        c2.plotly_chart(px.pie(df, names="synch_mode", hole=.45,
                               title="Synch vs Asynch"),
                        use_container_width=True)

    if {"volumetrie_an", "reussite", "complexite_cat"}.issubset(df):
        st.plotly_chart(px.scatter(df, x="volumetrie_an", y="reussite",
                                   color="complexite_cat",
                                   hover_data=["nom"],
                                   labels={"reussite": "% rÃ©ussite"}),
                        use_container_width=True)

# â•â•â• 8. Tech-Stack â•â•â•
with tab_tech:
    st.header("ğŸ› ï¸ Techno / Vendor / Cloud")
    if "techno" in df:
        st.plotly_chart(px.bar(df["techno"].value_counts().reset_index(),
                               x="index", y="techno",
                               labels={"index": "Technologie",
                                       "techno": "Robots"},
                               title="Nombre de robots par techno"),
                        use_container_width=True)
    if "vendor" in df:
        st.plotly_chart(px.bar(df["vendor"].value_counts().reset_index(),
                               x="index", y="vendor",
                               labels={"index": "Vendor", "vendor": "Robots"},
                               title="Robots par vendor"),
                        use_container_width=True)
    if {"zone_fonctionnelle", "departement", "vendor"}.issubset(df):
        st.plotly_chart(px.sunburst(df, path=["zone_fonctionnelle",
                                              "departement", "vendor"],
                                    values="volumetrie_an"
                                            if "volumetrie_an" in df else None,
                                    title="Sunburst Zone / DÃ©partement / Vendor"),
                        use_container_width=True)

# â•â•â• 9. DonnÃ©es â•â•â•
with tab_data:
    st.subheader("ğŸ“‘ Profil de table")
    st.dataframe(profile(df), use_container_width=True)

    st.subheader("ğŸ—ƒï¸ DonnÃ©es filtrÃ©es")
    st.dataframe(df, use_container_width=True, height=450)

    @st.cache_data
    def to_csv(d: pd.DataFrame): return d.to_csv(index=False).encode()

    st.download_button("ğŸ’¾ TÃ©lÃ©charger CSV filtrÃ©",
                       to_csv(df), "robots_filtered.csv",
                       "text/csv")

# â•â•â•â•â•â•â•â•â• FOOTER â•â•â•â•â•â•â•â•â•
st.caption(f"RÃ©alisÃ© par {AUTHOR} â€¢ [Code]({REPO}/blob/main/streamlit_app.py) â€¢ Â© 2025 Generali / Avanade")
