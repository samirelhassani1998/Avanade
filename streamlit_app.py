# -*- coding: utf-8 -*-
"""
Streamlit â€“ Inventaire RPA Generali  (v3.5 â€¢ 2025-06-05)
Auteur : Samir El Hassani â€“ Avanade

âœ… Lit indiffÃ©remment un CSV (sÃ©parateur auto) *ou* la feuille 1 dâ€™un Excel  
âœ… RepÃ¨re dynamiquement la VRAIE ligne dâ€™en-tÃªtes (celle qui contient Â« Id Â» & Â« Nom Â»)  
âœ… Nettoie / renomme les colonnes (slugify) â†’  zone_fonctionnelle, volumetrie_an, reussite, â€¦  
âœ… Toutes les visualisations (9 onglets) fonctionnent mÃªme si certaines colonnes manquent  
"""

from __future__ import annotations
import csv, io, itertools, re, unicodedata, warnings, pathlib

import numpy as np
import pandas as pd
import scipy.stats as stats
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG
st.set_page_config("Inventaire RPA Generali", "ğŸ¤–", "wide")
pd.options.display.float_format = "{:,.2f}".format
alt.data_transformers.disable_max_rows()
AUTHOR = "Samir El Hassani"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ UTILS
def slugify(text: str) -> str:
    text = unicodedata.normalize("NFKD", str(text)).encode("ascii", "ignore").decode()
    return re.sub(r"_+", "_", re.sub(r"[^0-9a-z]+", "_", text.lower())).strip("_")

def read_any(buf) -> pd.DataFrame:
    """Lit Excel (1Ê³áµ‰ feuille) ou CSV (sÃ©parateur auto, engine='python')."""
    ext = pathlib.Path(buf.name).suffix.lower()
    if ext in (".xls", ".xlsx", ".xlsm"):
        return pd.read_excel(buf, sheet_name=0, dtype=str, keep_default_na=False)
    # CSV : dÃ©tection robuste du sÃ©parateur avec pandas engine python
    buf.seek(0)
    return pd.read_csv(buf, dtype=str, keep_default_na=False,
                       sep=None, engine="python")

def promote_header(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cherche la 1Ê³áµ‰ ligne qui contient Ã  la fois Â« Id Â» et Â« Nom Â».
    La transforme en en-tÃªtes et supprime les lignes prÃ©cÃ©dentes.
    """
    for i in range(min(10, len(df))):
        row = df.iloc[i].str.strip().str.lower()
        if {"id", "nom"}.issubset(set(row)):
            df = df.iloc[i + 1:].reset_index(drop=True)
            df.columns = row
            break
    return df

def to_num(s: pd.Series, pct=False):
    s = (s.astype(str)
            .str.replace("%", "", regex=False)
            .str.replace(",", "", regex=False)
            .str.replace(" ", "", regex=False)
            .str.strip())
    n = pd.to_numeric(s, errors="coerce")
    return n / 100 if pct else n

def clean(raw: pd.DataFrame) -> pd.DataFrame:
    df = promote_header(raw)
    df.dropna(axis=1, how="all", inplace=True)
    df.columns = [slugify(c) or f"col_{i}" for i, c in enumerate(df.columns)]

    # cast numÃ©riques
    mapping = {"volumetrie_an": False, "gains_etp": False, "reussite": True}
    for base, pct in mapping.items():
        col = next((c for c in df.columns if c.startswith(base)), None)
        if col:
            df[col] = to_num(df[col], pct)
            df.rename(columns={col: base}, inplace=True)

    # libellÃ©s dÃ©rivÃ©s
    if "synch_asynch" in df:
        df["synch_mode"] = df["synch_asynch"].str.lower().str.strip()

    if "complexite_s_m_l" in df:
        df["complexite_cat"] = (df["complexite_s_m_l"].str.upper().str[0]
                                .map({"S": "Small", "M": "Medium", "L": "Large"}))
    return df

@st.cache_data(show_spinner=False)
def profile(df: pd.DataFrame) -> pd.DataFrame:
    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        desc = df.describe(include="all")
    total = len(df)
    p = (desc.T.assign(dtype=df.dtypes.astype(str))
                 .reset_index().rename(columns={"index": "col"}))
    p["missing"] = total - pd.to_numeric(p["count"].fillna(0))
    p["missing_pct"] = (p["missing"] / total * 100).round(1)
    return p

@st.cache_data(show_spinner=False)
def corr_with_p(df: pd.DataFrame) -> pd.DataFrame:
    num = df.select_dtypes(np.number)
    out = []
    for a, b in itertools.combinations(num.columns, 2):
        valid = num[[a, b]].dropna()
        if len(valid) > 2:
            r, p = stats.pearsonr(valid[a], valid[b])
            out.append({"var_x": a, "var_y": b, "corr": r, "pval": p})
    return pd.DataFrame(out)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SIDEBAR : import
st.sidebar.header("ğŸ“‚ Import")
file = st.sidebar.file_uploader("Feuille 1 (Excel) ou CSV", ["csv", "xls", "xlsx", "xlsm"])
if not file:
    st.sidebar.info("â¡ï¸ DÃ©posez un fichier pour commencer"); st.stop()

df = clean(read_any(file))

if st.sidebar.checkbox("Voir toutes les colonnes ğŸŒ"):
    st.sidebar.write(df.columns.tolist())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FILTRES
with st.sidebar:
    st.markdown("### ğŸ›ï¸ Filtres")
    cat_map = {"zone_fonctionnelle": "Zone", "departement": "DÃ©partement",
               "complexite_cat": "ComplexitÃ©", "synch_mode": "Synch/Asynch"}
    for col, lab in cat_map.items():
        if col in df and df[col].notna().any():
            opts = sorted(df[col].dropna().unique())
            df = df[df[col].isin(st.multiselect(lab, opts, default=opts))]

    if "volumetrie_an" in df:
        vmin, vmax = float(df["volumetrie_an"].min()), float(df["volumetrie_an"].max())
        rng = st.slider("VolumÃ©trie/an", vmin, vmax, (vmin, vmax))
        df = df[df["volumetrie_an"].between(*rng)]

    if "reussite" in df:
        pct_low, pct_hi = st.slider("% rÃ©ussite", 0.0, 1.0, (0.0, 1.0))
        df = df[df["reussite"].between(pct_low, pct_hi)]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ KPI
st.success(f"{len(df):,} lignes â€“ {df.shape[1]} colonnes")
k1, k2, k3, k4, k5 = st.columns(5)
k1.metric("Robots", f"{len(df):,}")
if "volumetrie_an" in df:
    k2.metric("VolumÃ©trie totale", f"{df['volumetrie_an'].sum():,.0f}")
if "reussite" in df:
    k3.metric("MÃ©diane rÃ©ussite", f"{df['reussite'].median()*100:,.1f}%")
    k4.metric("RÃ©ussite < 60 %", (df["reussite"] < .6).sum())
if "gains_etp" in df:
    k5.metric("Gains ETP totaux", f"{df['gains_etp'].sum():,.1f}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ONGLETs
tabs = st.tabs(["Vue gÃ©nÃ©rale", "Distributions", "Relations", "Performance",
                "Heat-Zones", "Clustering", "ComplexitÃ©/Mode",
                "Tech-Stack", "DonnÃ©es"])
(tab_over, tab_dist, tab_rel, tab_perf,
 tab_heat, tab_clu, tab_comp, tab_tech, tab_data) = tabs

# â•â•â•â•â• 1. Vue gÃ©nÃ©rale
with tab_over:
    st.subheader("ğŸ“ˆ Pareto volumÃ©trie (Top 20)")
    if {"volumetrie_an", "nom"}.issubset(df):
        pareto = (df.dropna(subset=["volumetrie_an"])
                    .sort_values("volumetrie_an", ascending=False)
                    .reset_index(drop=True))
        pareto["cum"] = pareto["volumetrie_an"].cumsum()/pareto["volumetrie_an"].sum()
        st.altair_chart(
            alt.layer(
                alt.Chart(pareto.head(20)).mark_bar().encode(
                    x=alt.X("nom:N", sort="-y", axis=None),
                    y="volumetrie_an:Q", tooltip=["nom", "volumetrie_an"]),
                alt.Chart(pareto.head(20)).mark_line(point=True,
                                                     color="#E67E22").encode(
                    x="nom:N", y=alt.Y("cum:Q", axis=alt.Axis(format="%")),
                    tooltip=alt.Tooltip("cum:Q", format=".1%"))
            ).resolve_scale(y="independent"),
            use_container_width=True)

    if "zone_fonctionnelle" in df:
        st.dataframe(df.groupby("zone_fonctionnelle")
                       .agg(robots=("nom", "count"),
                            volumetrie=("volumetrie_an", "sum"),
                            reussite_moy=("reussite", "mean"))
                       .reset_index(),
                     hide_index=True, use_container_width=True)

# â•â•â•â•â• 2. Distributions
with tab_dist:
    st.subheader("ğŸ“Š Histogrammes & box-plots")
    numcols = df.select_dtypes(np.number).columns
    if numcols.any():
        var = st.selectbox("Variable numÃ©rique", numcols)
        c1, c2 = st.columns(2)
        c1.altair_chart(alt.Chart(df.dropna(subset=[var]))
                          .mark_bar().encode(x=alt.X(var, bin=True), y='count()'),
                          use_container_width=True)
        c2.altair_chart(alt.Chart(df.dropna(subset=[var]))
                          .mark_boxplot(extent="min-max").encode(y=var),
                          use_container_width=True)
    else:
        st.info("Pas de numÃ©rique.")

# â•â•â•â•â• 3. Relations
with tab_rel:
    st.subheader("ğŸ”— CorrÃ©lations")
    if df.select_dtypes(np.number).shape[1] >= 2:
        heat = corr_with_p(df)
        if not heat.empty:
            st.altair_chart(
                alt.Chart(heat).mark_rect().encode(
                    x="var_x:O", y="var_y:O",
                    color=alt.Color("corr:Q", scale=alt.Scale(scheme="viridis")),
                    tooltip=[alt.Tooltip("corr:Q", format=".2f"),
                             alt.Tooltip("pval:Q", format=".1e")]),
                use_container_width=True)

    if {"volumetrie_an", "reussite"}.issubset(df):
        st.subheader("Scatter Volume vs % rÃ©ussite")
        st.altair_chart(
            (alt.Chart(df.dropna(subset=["volumetrie_an", "reussite"]))
                 .mark_circle(size=70, opacity=.6)
                 .encode(x="volumetrie_an", y=alt.Y("reussite",
                                                    axis=alt.Axis(format="%")),
                         tooltip=["nom"]))
            + (alt.Chart(df).transform_regression("volumetrie_an", "reussite")
                 .mark_line(color="red")),
            use_container_width=True)

# â•â•â•â•â• 4. Performance
with tab_perf:
    st.subheader("ğŸ“ Ajustement normal")
    numcols = df.select_dtypes(np.number).columns
    if numcols.any():
        choice = st.selectbox("Variable", numcols)
        series = df[choice].dropna()
        if len(series) > 3:
            mu, sd = series.mean(), series.std()
            xs = np.linspace(series.min(), series.max(), 200)
            fig = go.Figure()
            fig.add_histogram(x=series, nbinsx=40, histnorm="probability density")
            fig.add_scatter(x=xs, y=stats.norm.pdf(xs, mu, sd), mode="lines")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Pas assez de valeurs.")

# â•â•â•â•â• 5. Heat-Zones
with tab_heat:
    st.subheader("ğŸŒ¡ï¸ Zones vs classes de rÃ©ussite")
    required = {"zone_fonctionnelle", "reussite", "volumetrie_an"}
    if required.issubset(df):
        df["classe"] = pd.cut(df["reussite"], [0, .6, .8, 1.01],
                              labels=["<60 %", "60-80 %", "â‰¥80 %"],
                              include_lowest=True)
        mode = st.radio("Couleur par â€¦", ["Nombre", "VolumÃ©trie"], horizontal=True)
        if mode == "Nombre":
            pivot = (df.groupby(["zone_fonctionnelle", "classe"])
                       .size().reset_index(name="val"))
            titre = "Robots"
        else:
            pivot = (df.groupby(["zone_fonctionnelle", "classe"])
                       ["volumetrie_an"].sum().reset_index(name="val"))
            titre = "VolumÃ©trie"
        st.altair_chart(alt.Chart(pivot).mark_rect().encode(
            x="classe:N", y="zone_fonctionnelle:N",
            color=alt.Color("val:Q", scale=alt.Scale(scheme="blues"), title=titre),
            tooltip=["zone_fonctionnelle:N", "classe:N",
                     alt.Tooltip("val:Q", format=",.0f")]),
            use_container_width=True)
    else:
        st.info("Colonnes indispensables absentes.")

# â•â•â•â•â• 6. Clustering
with tab_clu:
    st.subheader("ğŸ¯ K-means")
    sel = [c for c in ("volumetrie_an", "reussite", "gains_etp") if c in df]
    data = df[sel].dropna()
    if data.shape[0] >= 5 and data.shape[1] >= 2:
        k = st.slider("k", 2, 6, 3)
        km = KMeans(n_clusters=k, n_init="auto", random_state=0)
        df.loc[data.index, "cluster"] = km.fit_predict(StandardScaler().fit_transform(data))
        st.metric("Inertie", f"{km.inertia_:,.0f}")
        x, y = st.selectbox("X", sel, 0), st.selectbox("Y", sel, 1)
        st.plotly_chart(px.scatter(df, x=x, y=y, color="cluster",
                                   hover_data=["nom"]), use_container_width=True)
    else:
        st.info("â‰¥ 5 lignes & 2 variables requises.")

# â•â•â•â•â• 7. ComplexitÃ© / Mode
with tab_comp:
    st.header("ğŸ” ComplexitÃ© & Synch/Asynch")
    if "complexite_cat" in df:
        st.plotly_chart(px.pie(df, names="complexite_cat", hole=.45,
                               title="RÃ©partition par complexitÃ©"),
                        use_container_width=True)
    if "synch_mode" in df:
        st.plotly_chart(px.pie(df, names="synch_mode", hole=.45,
                               title="Synch / Asynch"),
                        use_container_width=True)
    if {"volumetrie_an", "reussite", "complexite_cat"}.issubset(df):
        st.plotly_chart(px.scatter(df, x="volumetrie_an", y="reussite",
                                   color="complexite_cat"), use_container_width=True)

# â•â•â•â•â• 8. Tech-Stack
with tab_tech:
    st.header("ğŸ› ï¸ Techno / Vendor / Cloud")
    if "techno" in df:
        st.plotly_chart(px.bar(df["techno"].value_counts().reset_index(),
                               x="index", y="techno",
                               labels={"index": "Technologie", "techno": "Robots"}),
                        use_container_width=True)
    if "vendor" in df:
        st.plotly_chart(px.bar(df["vendor"].value_counts().reset_index(),
                               x="index", y="vendor",
                               labels={"index": "Vendor", "vendor": "Robots"}),
                        use_container_width=True)
    if {"zone_fonctionnelle", "departement", "vendor"}.issubset(df):
        st.plotly_chart(px.sunburst(df, path=["zone_fonctionnelle",
                                              "departement", "vendor"],
                                    values="volumetrie_an"
                                     if "volumetrie_an" in df else None),
                        use_container_width=True)

# â•â•â•â•â• 9. DonnÃ©es
with tab_data:
    st.subheader("Profil")
    st.dataframe(profile(df), use_container_width=True)

    st.subheader("Table filtrÃ©e")
    st.dataframe(df, use_container_width=True, height=450)

    @st.cache_data
    def to_csv(d: pd.DataFrame): return d.to_csv(index=False).encode()

    st.download_button("ğŸ’¾ Exporter CSV", to_csv(df), "robots_filtered.csv",
                       "text/csv")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FOOTER
st.caption(f"RÃ©alisÃ© par {AUTHOR} â€¢ Â© 2025 Generali / Avanade")
